{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_Himanshu.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ez_UyXDOkoMH","colab_type":"code","colab":{}},"source":["#Import the dependencies\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CS6eN20gmDC0","colab_type":"code","outputId":"76650b1a-cedf-46a1-c31c-0d35000bbb61","colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["# Import the dataset\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets('MNIST_data')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zMWRHgY5mJqF","colab_type":"code","colab":{}},"source":["tf.reset_default_graph()\n","batch_size = 200\n","n_noise = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CK3cSTpvktFV","colab_type":"code","colab":{}},"source":["#Define the Placeholders\n","samples = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='X')\n","noise = tf.placeholder(dtype=tf.float32, shape=[None, n_noise])\n","\n","keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n","is_train = tf.placeholder(dtype=tf.bool, name='is_train')\n","\n","def lrelu(x):\n","    return tf.maximum(x, tf.multiply(x, 0.2))\n","\n","def binary_cross_entropy(x, z):\n","    eps = 1e-12\n","    return (-(x * tf.log(z + eps) + (1. - x) * tf.log(1. - z + eps)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rDgo4-elFli","colab_type":"code","colab":{}},"source":["def discriminator(samples, reuse=None, keep_prob=keep_prob):\n","    activation = lrelu\n","    with tf.variable_scope(\"discriminator\", reuse=reuse):\n","        reshape = tf.reshape(samples, shape=[-1, 28, 28, 1])\n","        conv_1 = tf.layers.conv2d(reshape, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n","        a_1 = tf.layers.dropout(conv_1, keep_prob)\n","        conv_2 = tf.layers.conv2d(a_1, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n","        a_2 = tf.layers.dropout(conv_2, keep_prob)\n","        conv_3 = tf.layers.conv2d(a_2, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n","        a_3 = tf.layers.dropout(conv_3, keep_prob)\n","        flatten = tf.contrib.layers.flatten(a_3)\n","        fc_1 = tf.layers.dense(flatten, units=128, activation=activation)\n","        y = tf.layers.dense(fc_1, units=1, activation=tf.nn.sigmoid)\n","        return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fliKe8EylV7w","colab_type":"code","colab":{}},"source":["def generator(z, keep_prob=keep_prob, is_train=is_train):\n","    activation = lrelu\n","    momentum = 0.99\n","    with tf.variable_scope(\"generator\", reuse=None):\n","\n","        fc_1 = tf.layers.dense(z, units=7 * 7 * 1, activation=activation)\n","        z_1 = tf.layers.dropout(fc_1, keep_prob)      \n","        a_1 = tf.contrib.layers.batch_norm(z_1, is_training=is_train, decay=momentum)  \n","        reshape = tf.reshape(a_1, shape=[-1,7,7,1])\n","        convt_1 = tf.layers.conv2d_transpose(reshape, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n","        z_2 = tf.layers.dropout(convt_1, keep_prob)\n","        a_2 = tf.contrib.layers.batch_norm(z_2, is_training=is_train, decay=momentum)\n","        convt_2 = tf.layers.conv2d_transpose(a_2, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n","        z_3 = tf.layers.dropout(convt_2, keep_prob)\n","        a_3 = tf.contrib.layers.batch_norm(z_3, is_training=is_train, decay=momentum)\n","        convt_3 = tf.layers.conv2d_transpose(a_3, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n","        z_3 = tf.layers.dropout(convt_3, keep_prob)\n","        a_3 = tf.contrib.layers.batch_norm(z_3, is_training=is_train, decay=momentum)\n","        img = tf.layers.conv2d_transpose(a_3, kernel_size=5, filters=1, strides=1, padding='same', activation=tf.nn.sigmoid)\n","        return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Haj57g3flZXK","colab_type":"code","colab":{}},"source":["g = generator(noise, keep_prob, is_train)\n","d_real = discriminator(samples)\n","d_fake = discriminator(g, reuse=True)\n","\n","vars_g = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\n","vars_d = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\n","\n","loss_d_real = binary_cross_entropy(tf.ones_like(d_real), d_real)\n","loss_d_fake = binary_cross_entropy(tf.zeros_like(d_fake), d_fake)\n","loss_g = tf.reduce_mean(binary_cross_entropy(tf.ones_like(d_fake), d_fake))\n","loss_d = tf.reduce_mean(0.5 * (loss_d_real + loss_d_fake))\n","\n","update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","with tf.control_dependencies(update_ops):\n","    optimizer_d = tf.train.AdamOptimizer(learning_rate=0.00015).minimize(loss_d, var_list=vars_d)\n","    optimizer_g = tf.train.AdamOptimizer(learning_rate=0.00015).minimize(loss_g, var_list=vars_g)\n","    \n","    \n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0nDz61XxZ4q","colab_type":"code","outputId":"71941840-744b-46dc-cff1-f958217fcfb9","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for e in range(64):\n","  start = time.time()\n","  for i in range(300):\n","    \n","    train_d = True\n","    train_g = True\n","    keep_prob_train = 0.6 # 0.5\n","\n","\n","    n = np.random.uniform(0.0, 1.0, [batch_size, n_noise]).astype(np.float32)   \n","    batch = [np.reshape(b, [28, 28]) for b in mnist.train.next_batch(batch_size=batch_size)[0]]  \n","\n","    d_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={samples: batch, noise: n, keep_prob: keep_prob_train, is_train:True})\n","\n","    d_real_ls = np.mean(d_real_ls)\n","    d_fake_ls = np.mean(d_fake_ls)\n","    g_ls = g_ls\n","    d_ls = d_ls\n","\n","\n","\n","    if g_ls * 1.5 < d_ls:\n","        train_g = False\n","        pass\n","    if d_ls * 2 < g_ls:\n","        train_d = False\n","        pass\n","\n","    if train_d:\n","        sess.run(optimizer_d, feed_dict={noise: n, samples: batch, keep_prob: keep_prob_train, is_train:True})\n","\n","\n","    if train_g:\n","        sess.run(optimizer_g, feed_dict={noise: n, keep_prob: keep_prob_train, is_train:True})\n","        \n","  print('Epoch %i: g_ls: %f, d_ls: %f, time: %f sec' %(e + 1, g_ls, d_ls, time.time()-start))\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1: g_ls: 1.201799, d_ls: 0.504896, time: 25.501716 sec\n","Epoch 2: g_ls: 1.030253, d_ls: 0.498521, time: 27.016354 sec\n","Epoch 3: g_ls: 1.408460, d_ls: 0.557006, time: 24.883064 sec\n","Epoch 4: g_ls: 1.353331, d_ls: 0.565302, time: 25.281621 sec\n","Epoch 5: g_ls: 1.226494, d_ls: 0.502723, time: 25.701084 sec\n","Epoch 6: g_ls: 1.226020, d_ls: 0.579215, time: 24.548136 sec\n","Epoch 7: g_ls: 1.251517, d_ls: 0.593398, time: 25.483096 sec\n","Epoch 8: g_ls: 0.993377, d_ls: 0.581727, time: 26.553833 sec\n","Epoch 9: g_ls: 1.174749, d_ls: 0.527826, time: 26.280526 sec\n","Epoch 10: g_ls: 1.037638, d_ls: 0.538234, time: 26.128504 sec\n","Epoch 11: g_ls: 1.071553, d_ls: 0.515133, time: 26.194490 sec\n","Epoch 12: g_ls: 1.150298, d_ls: 0.501959, time: 26.819019 sec\n","Epoch 13: g_ls: 1.171506, d_ls: 0.559933, time: 25.906101 sec\n","Epoch 14: g_ls: 1.127486, d_ls: 0.511920, time: 27.957858 sec\n","Epoch 15: g_ls: 1.062177, d_ls: 0.533741, time: 25.652077 sec\n","Epoch 16: g_ls: 1.106881, d_ls: 0.540691, time: 26.473718 sec\n","Epoch 17: g_ls: 1.092820, d_ls: 0.561060, time: 27.816826 sec\n","Epoch 18: g_ls: 1.007284, d_ls: 0.557130, time: 26.965852 sec\n","Epoch 19: g_ls: 1.137087, d_ls: 0.602113, time: 26.803855 sec\n","Epoch 20: g_ls: 1.115658, d_ls: 0.545194, time: 27.410200 sec\n","Epoch 21: g_ls: 1.022303, d_ls: 0.554315, time: 27.136283 sec\n","Epoch 22: g_ls: 1.213843, d_ls: 0.495439, time: 27.381011 sec\n","Epoch 23: g_ls: 1.062952, d_ls: 0.561383, time: 27.591767 sec\n","Epoch 24: g_ls: 1.082940, d_ls: 0.580680, time: 26.862524 sec\n","Epoch 25: g_ls: 1.131729, d_ls: 0.533484, time: 27.960780 sec\n","Epoch 26: g_ls: 1.026293, d_ls: 0.558702, time: 27.725812 sec\n","Epoch 27: g_ls: 1.117861, d_ls: 0.486059, time: 28.295439 sec\n","Epoch 28: g_ls: 1.094897, d_ls: 0.561234, time: 27.499347 sec\n","Epoch 29: g_ls: 1.095171, d_ls: 0.529767, time: 27.723593 sec\n","Epoch 30: g_ls: 1.043725, d_ls: 0.538653, time: 27.555164 sec\n","Epoch 31: g_ls: 0.984574, d_ls: 0.594852, time: 27.666074 sec\n","Epoch 32: g_ls: 0.961825, d_ls: 0.568126, time: 28.169206 sec\n","Epoch 33: g_ls: 1.063273, d_ls: 0.529409, time: 28.484676 sec\n","Epoch 34: g_ls: 1.092451, d_ls: 0.552653, time: 27.873956 sec\n","Epoch 35: g_ls: 1.158727, d_ls: 0.556561, time: 27.863964 sec\n","Epoch 36: g_ls: 1.115333, d_ls: 0.553653, time: 28.282534 sec\n","Epoch 37: g_ls: 1.116691, d_ls: 0.521467, time: 27.255376 sec\n","Epoch 38: g_ls: 1.056674, d_ls: 0.528327, time: 28.098631 sec\n","Epoch 39: g_ls: 1.109281, d_ls: 0.548615, time: 27.531586 sec\n","Epoch 40: g_ls: 1.160263, d_ls: 0.533578, time: 28.059505 sec\n","Epoch 41: g_ls: 0.937404, d_ls: 0.520901, time: 28.274183 sec\n","Epoch 42: g_ls: 1.139664, d_ls: 0.516976, time: 28.047590 sec\n","Epoch 43: g_ls: 1.132507, d_ls: 0.516634, time: 28.212517 sec\n","Epoch 44: g_ls: 1.123561, d_ls: 0.515916, time: 28.234872 sec\n","Epoch 45: g_ls: 1.110612, d_ls: 0.522926, time: 27.831512 sec\n","Epoch 46: g_ls: 1.129537, d_ls: 0.529009, time: 27.893289 sec\n","Epoch 47: g_ls: 1.036564, d_ls: 0.544036, time: 27.487714 sec\n","Epoch 48: g_ls: 1.141077, d_ls: 0.542184, time: 27.455096 sec\n","Epoch 49: g_ls: 1.347416, d_ls: 0.647569, time: 27.251909 sec\n","Epoch 50: g_ls: 1.126140, d_ls: 0.548976, time: 27.299329 sec\n","Epoch 51: g_ls: 1.139207, d_ls: 0.593315, time: 27.294098 sec\n","Epoch 52: g_ls: 1.224714, d_ls: 0.504430, time: 27.869673 sec\n","Epoch 53: g_ls: 0.972009, d_ls: 0.576299, time: 27.734254 sec\n","Epoch 54: g_ls: 1.285179, d_ls: 0.494566, time: 27.191218 sec\n","Epoch 55: g_ls: 1.052386, d_ls: 0.513975, time: 27.250286 sec\n","Epoch 56: g_ls: 1.095917, d_ls: 0.572778, time: 27.806955 sec\n","Epoch 57: g_ls: 1.073918, d_ls: 0.538274, time: 27.344181 sec\n","Epoch 58: g_ls: 1.163085, d_ls: 0.564522, time: 26.533427 sec\n","Epoch 59: g_ls: 1.248100, d_ls: 0.503958, time: 28.052249 sec\n","Epoch 60: g_ls: 1.177286, d_ls: 0.557774, time: 27.485420 sec\n","Epoch 61: g_ls: 1.138172, d_ls: 0.542865, time: 27.155054 sec\n","Epoch 62: g_ls: 1.055363, d_ls: 0.565767, time: 26.377342 sec\n","Epoch 63: g_ls: 1.150916, d_ls: 0.557541, time: 26.712696 sec\n","Epoch 64: g_ls: 1.298738, d_ls: 0.526374, time: 26.830427 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"19n3UyiWp5ic","colab_type":"code","colab":{}},"source":["test_noise = np.random.normal(0,1,[100,100])\n","test_output = sess.run(g, feed_dict = {noise: test_noise, is_train: False, keep_prob: 0.6 })"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtzgO7ARp6Ij","colab_type":"code","outputId":"2499dad7-d31f-4e81-fb7e-b90689de2795","colab":{"base_uri":"https://localhost:8080/","height":287}},"source":["plt.imshow(test_output[90,:,:,0], cmap = 'gray')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f22763659b0>"]},"metadata":{"tags":[]},"execution_count":98},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"5WW9zsg2p8Nw","colab_type":"code","outputId":"03d82737-933c-49af-d011-18b65a29ed17","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x1.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64, 28, 28)"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"_62OA2gAqK7r","colab_type":"code","outputId":"4a5dce96-0adc-4594-e203-b61206549061","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["5%300"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"3OmZj7mNxV0-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}